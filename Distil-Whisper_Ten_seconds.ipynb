{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7606132-655e-4cad-9e89-1458db431e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50360]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " on this former industrial site in Whitehaven, Cumbria, planned to produce 60 million tonnes of new coal. But since it was approved, a Supreme Court ruling found projects  consider carbon emissions from burning fossil fuels, not just digging them up. The mine was the first legal test of that. It's been a really important victory.  But what frustrates me most is that the years' decision makers have been putting all their efforts and fighting for a coal mine in Whitehaven. They could have spent that time investing in green jobs.  But it was mining jobs the community expected. This site has sat empty for 20 years. It's devastating for the community. The jobs that were going to be created were  possibly in the construction and supply chain surrounding it were probably around 2000 and the long-term well-paid jobs for running the facility  in excess of 500. The new government has been clear about its net zero ambitions, but judgments like this one could test them. We're still reliance on  Thank you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import librosa\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "import soundfile as sf\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"distil-whisper/distil-large-v3\"\n",
    "\n",
    "# Load the model and processor\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True, attn_implementation=\"sdpa\"\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# Create the ASR pipeline\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Load the audio file using librosa\n",
    "audio_file = \"/home/vmadmin/myenv/English/1010834_2024.09.14_08.06.27-2024.09.14_08.07.27.wav\"\n",
    "waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Define the chunk duration in seconds\n",
    "chunk_duration = 10\n",
    "num_samples_per_chunk = chunk_duration * sample_rate\n",
    "\n",
    "# Split the audio into chunks\n",
    "chunks = []\n",
    "for start in range(0, len(waveform), num_samples_per_chunk):\n",
    "    end = min(start + num_samples_per_chunk, len(waveform))\n",
    "    chunk = waveform[start:end]\n",
    "    chunks.append(chunk)\n",
    "\n",
    "# Transcribe each chunk\n",
    "transcriptions = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    # Save the chunk to a temporary file\n",
    "    chunk_file = f\"temp_chunk_{i}.wav\"\n",
    "    sf.write(chunk_file, chunk, sample_rate)\n",
    "\n",
    "    # Run the ASR pipeline on the chunk\n",
    "    result = pipe(chunk_file, batch_size=8, return_timestamps=False)\n",
    "    transcriptions.append(result[\"text\"])\n",
    "\n",
    "# Combine transcriptions\n",
    "full_transcription = \" \".join(transcriptions)\n",
    "print(full_transcription)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b74a499-8a97-4b79-afd3-b48024d99685",
   "metadata": {},
   "source": [
    "# Correct One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e60c750b-fb34-4160-af91-91b3754ee03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50360]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s - 10.00s]  on this former industrial site in Whitehaven, Cumbria, planned to produce 60 million tonnes of new coal. But since it was approved, a Supreme Court ruling found projects\n",
      "[10.00s - 20.00s]  consider carbon emissions from burning fossil fuels, not just digging them up. The mine was the first legal test of that. It's been a really important victory.\n",
      "[20.00s - 30.00s]  But what frustrates me most is that the years local decision makers have been putting all their efforts and fighting for a coal mine in Whitehaven. They could have spent that time investing in green jobs.\n",
      "[30.00s - 40.00s]  But it was mining jobs the community expected. This site has sat empty for 20 years. It's devastating for the community. The jobs that were going to be created were\n",
      "[40.00s - 50.00s]  Possibly in the construction and supply chain surrounding it were probably around 2000. And the long-term, well-paid jobs for running the facility work.\n",
      "[50.00s - 60.00s]  in excess of 500. The new government has been clear about its net zero ambitions, but judgments like this one could test them. We're still reliance on\n",
      "[60.00s - 60.01s]  I'm going to be.\n",
      "\n",
      "Full Transcription:\n",
      " on this former industrial site in Whitehaven, Cumbria, planned to produce 60 million tonnes of new coal. But since it was approved, a Supreme Court ruling found projects  consider carbon emissions from burning fossil fuels, not just digging them up. The mine was the first legal test of that. It's been a really important victory.  But what frustrates me most is that the years local decision makers have been putting all their efforts and fighting for a coal mine in Whitehaven. They could have spent that time investing in green jobs.  But it was mining jobs the community expected. This site has sat empty for 20 years. It's devastating for the community. The jobs that were going to be created were  Possibly in the construction and supply chain surrounding it were probably around 2000. And the long-term, well-paid jobs for running the facility work.  in excess of 500. The new government has been clear about its net zero ambitions, but judgments like this one could test them. We're still reliance on  I'm going to be.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import librosa\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "import soundfile as sf\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"distil-whisper/distil-large-v3\"\n",
    "\n",
    "# Load the model and processor\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True, attn_implementation=\"sdpa\"\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# Create the ASR pipeline\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Load the audio file using librosa\n",
    "audio_file = \"/home/vmadmin/myenv/English/1010834_2024.09.14_08.06.27-2024.09.14_08.07.27.wav\"\n",
    "waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Define the chunk duration in seconds\n",
    "chunk_duration = 10\n",
    "num_samples_per_chunk = chunk_duration * sample_rate\n",
    "\n",
    "# Split the audio into chunks\n",
    "chunks = []\n",
    "for start in range(0, len(waveform), num_samples_per_chunk):\n",
    "    end = min(start + num_samples_per_chunk, len(waveform))\n",
    "    chunk = waveform[start:end]\n",
    "    chunks.append((chunk, start / sample_rate, end / sample_rate))  # Include timestamps\n",
    "\n",
    "# Transcribe each chunk\n",
    "transcriptions = []\n",
    "for i, (chunk, start_time, end_time) in enumerate(chunks):\n",
    "    # Save the chunk to a temporary file\n",
    "    chunk_file = f\"temp_chunk_{i}.wav\"\n",
    "    sf.write(chunk_file, chunk, sample_rate)\n",
    "\n",
    "    # Run the ASR pipeline on the chunk\n",
    "    result = pipe(chunk_file, batch_size=8, return_timestamps=True)  # Set to True for timestamps\n",
    "    transcriptions.append((result[\"text\"], start_time, end_time))\n",
    "\n",
    "# Print the transcriptions with timestamps\n",
    "for text, start_time, end_time in transcriptions:\n",
    "    print(f\"[{start_time:.2f}s - {end_time:.2f}s] {text}\")\n",
    "\n",
    "# Optional: Combine transcriptions if needed\n",
    "full_transcription = \" \".join(text for text, _, _ in transcriptions)\n",
    "print(\"\\nFull Transcription:\")\n",
    "print(full_transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34ba7310-0b2e-49d7-9007-fe4fcd96b9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56923d9d-4e7f-468a-af85-990ed9c6059a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16955/735786769.py:3: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "[src/libmpg123/parse.c:skip_junk():1276] error: Giving up searching valid MPEG header after 65536 bytes of junk.\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s - 10.00s]  And as I bring you all the latest from the world of sports. Take a look. And all-run performance by India.\n",
      "[10.00s - 20.00s]  beat Australia by 36 runs in the second semi-final of the ICC Women's World Cup on Thursday at Derby.\n",
      "[20.00s - 30.00s]  Hermann Preet Kord produced one of the greatest ever ODIR Knox in women's cricket as India stormed into\n",
      "[30.00s - 40.00s]  the final. Herman Preet's third ODIS century was embellished with 24s and as many as 7-6s.\n",
      "[40.00s - 50.00s]  It is the second time that India has entered the summit clash of the global event having lost to Australia in the final of the 2020.\n",
      "[50.00s - 60.00s]  2005 edition. It was also the second highest individual score in ODIs for India.\n",
      "[60.00s - 70.00s]  behind Dik Tisharmas and beat in 188 runs against South Africa earlier this year. With enough runs on the board, confident Indian seamer\n",
      "[70.00s - 78.30s]  Goswami and Shikha Pande came up with brilliant opening spells.\n",
      "\n",
      "Full Transcription:\n",
      " And as I bring you all the latest from the world of sports. Take a look. And all-run performance by India.  beat Australia by 36 runs in the second semi-final of the ICC Women's World Cup on Thursday at Derby.  Hermann Preet Kord produced one of the greatest ever ODIR Knox in women's cricket as India stormed into  the final. Herman Preet's third ODIS century was embellished with 24s and as many as 7-6s.  It is the second time that India has entered the summit clash of the global event having lost to Australia in the final of the 2020.  2005 edition. It was also the second highest individual score in ODIs for India.  behind Dik Tisharmas and beat in 188 runs against South Africa earlier this year. With enough runs on the board, confident Indian seamer  Goswami and Shikha Pande came up with brilliant opening spells.\n",
      "\n",
      "Total Processing Time: 1.81 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the audio file using librosa\n",
    "audio_file = \"/home/vmadmin/myenv/English/clip1.mp3\"\n",
    "waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Define the chunk duration in seconds\n",
    "chunk_duration = 10\n",
    "num_samples_per_chunk = chunk_duration * sample_rate\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Split the audio into chunks\n",
    "chunks = []\n",
    "for start in range(0, len(waveform), num_samples_per_chunk):\n",
    "    end = min(start + num_samples_per_chunk, len(waveform))\n",
    "    chunk = waveform[start:end]\n",
    "    chunks.append((chunk, start / sample_rate, end / sample_rate))  # Include timestamps\n",
    "\n",
    "# Transcribe each chunk\n",
    "transcriptions = []\n",
    "for i, (chunk, start_time_chunk, end_time_chunk) in enumerate(chunks):\n",
    "    # Save the chunk to a temporary file\n",
    "    chunk_file = f\"temp_chunk_{i}.wav\"\n",
    "    sf.write(chunk_file, chunk, sample_rate)\n",
    "\n",
    "    # Run the ASR pipeline on the chunk\n",
    "    result = pipe(chunk_file, batch_size=8, return_timestamps=True)  # Set to True for timestamps\n",
    "    transcriptions.append((result[\"text\"], start_time_chunk, end_time_chunk))\n",
    "\n",
    "# Stop timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Print the transcriptions with timestamps\n",
    "for text, start_time_chunk, end_time_chunk in transcriptions:\n",
    "    print(f\"[{start_time_chunk:.2f}s - {end_time_chunk:.2f}s] {text}\")\n",
    "\n",
    "# Optional: Combine transcriptions if needed\n",
    "full_transcription = \" \".join(text for text, _, _ in transcriptions)\n",
    "print(\"\\nFull Transcription:\")\n",
    "print(full_transcription)\n",
    "\n",
    "# Print total processed time\n",
    "print(f\"\\nTotal Processing Time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9c49017-f508-41b3-b487-8b1da0b65ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16955/2688234124.py:3: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "[src/libmpg123/parse.c:skip_junk():1276] error: Giving up searching valid MPEG header after 65536 bytes of junk.\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s - 10.00s]  Moving now to some tragic news coming in from Jammu and Kashmir. Well, right ahead of the Prime Minister's visit a major encounter in Jambun Kishmir's Kishthwar. In fact, tragically, two soldiers.\n",
      "[10.00s - 20.00s]  have died in the line of duty. In fact, several other soldiers have been injured as well. There was a brief gunfight is what we can report at this moment.\n",
      "[20.00s - 30.00s]  in Jammu Kishmir's Kistvar and two soldiers have died. Of course, these are soldiers leading from the front and they've been killed in the line of action,\n",
      "[30.00s - 40.00s]  tragic there and this comes after there was a major arms hall as well in parts of Jammu in Kashmir and the timing of the encounter is also extremely important given the fact\n",
      "[40.00s - 50.00s]  that this comes right ahead of the assembly polls. The assembly pole just a week away, less than a week away perhaps. The first phase will be held on the 18th\n",
      "[50.00s - 60.00s]  of September, so extremely concerning there and most tragic the fact that two soldiers have died in this gun battle.\n",
      "[60.00s - 61.63s]  Thank you.\n",
      "\n",
      "Full Transcription:\n",
      " Moving now to some tragic news coming in from Jammu and Kashmir. Well, right ahead of the Prime Minister's visit a major encounter in Jambun Kishmir's Kishthwar. In fact, tragically, two soldiers.  have died in the line of duty. In fact, several other soldiers have been injured as well. There was a brief gunfight is what we can report at this moment.  in Jammu Kishmir's Kistvar and two soldiers have died. Of course, these are soldiers leading from the front and they've been killed in the line of action,  tragic there and this comes after there was a major arms hall as well in parts of Jammu in Kashmir and the timing of the encounter is also extremely important given the fact  that this comes right ahead of the assembly polls. The assembly pole just a week away, less than a week away perhaps. The first phase will be held on the 18th  of September, so extremely concerning there and most tragic the fact that two soldiers have died in this gun battle.  Thank you.\n",
      "\n",
      "Total Processing Time: 1.83 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load the audio file using librosa\n",
    "audio_file = \"/home/vmadmin/myenv/English/clip2.mp3\"\n",
    "waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Define the chunk duration in seconds\n",
    "chunk_duration = 10\n",
    "num_samples_per_chunk = chunk_duration * sample_rate\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Split the audio into chunks\n",
    "chunks = []\n",
    "for start in range(0, len(waveform), num_samples_per_chunk):\n",
    "    end = min(start + num_samples_per_chunk, len(waveform))\n",
    "    chunk = waveform[start:end]\n",
    "    chunks.append((chunk, start / sample_rate, end / sample_rate))  # Include timestamps\n",
    "\n",
    "# Transcribe each chunk\n",
    "transcriptions = []\n",
    "for i, (chunk, start_time_chunk, end_time_chunk) in enumerate(chunks):\n",
    "    # Save the chunk to a temporary file\n",
    "    chunk_file = f\"temp_chunk_{i}.wav\"\n",
    "    sf.write(chunk_file, chunk, sample_rate)\n",
    "\n",
    "    # Run the ASR pipeline on the chunk\n",
    "    result = pipe(chunk_file, batch_size=8, return_timestamps=True)  # Set to True for timestamps\n",
    "    transcriptions.append((result[\"text\"], start_time_chunk, end_time_chunk))\n",
    "\n",
    "# Stop timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Print the transcriptions with timestamps\n",
    "for text, start_time_chunk, end_time_chunk in transcriptions:\n",
    "    print(f\"[{start_time_chunk:.2f}s - {end_time_chunk:.2f}s] {text}\")\n",
    "\n",
    "# Optional: Combine transcriptions if needed\n",
    "full_transcription = \" \".join(text for text, _, _ in transcriptions)\n",
    "print(\"\\nFull Transcription:\")\n",
    "print(full_transcription)\n",
    "\n",
    "# Print total processed time\n",
    "print(f\"\\nTotal Processing Time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea2ad0c4-a603-442a-8b34-8ce814b6ab85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16955/1764927414.py:3: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "[src/libmpg123/parse.c:skip_junk():1276] error: Giving up searching valid MPEG header after 65536 bytes of junk.\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s - 10.00s]  When I was shocked to go to the Howe it would be on the without a heart of I won't championship in a medal\n",
      "[10.00s - 20.00s]  I didn't know that Periarchic\n",
      "[20.00s - 30.00s]  what was what was. A trial was Pera then I got that the Paira are different and the Able's different.\n",
      "[30.00s - 40.00s]  I had to know that the perjury also, I thought I'd say I'd say I'd say all right. And I'm not even though\n",
      "[40.00s - 50.00s]  you can't do you can't you can't do you do you're doing so I'm doing then I'm doing a little up\n",
      "[50.00s - 60.00s]  I had to do it easy to do it. Strength, 6, 7 hours we practiced. Then I was I was in the goal, then I went to\n",
      "[60.00s - 70.00s]  I was one-being. When I was in the I was there I would be I would be I could do something that I gave one thing\n",
      "[70.00s - 74.81s]  Thank you.\n",
      "\n",
      "Full Transcription:\n",
      " When I was shocked to go to the Howe it would be on the without a heart of I won't championship in a medal  I didn't know that Periarchic  what was what was. A trial was Pera then I got that the Paira are different and the Able's different.  I had to know that the perjury also, I thought I'd say I'd say I'd say all right. And I'm not even though  you can't do you can't you can't do you do you're doing so I'm doing then I'm doing a little up  I had to do it easy to do it. Strength, 6, 7 hours we practiced. Then I was I was in the goal, then I went to  I was one-being. When I was in the I was there I would be I would be I could do something that I gave one thing  Thank you.\n",
      "\n",
      "Total Processing Time: 1.90 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the audio file using librosa\n",
    "audio_file = \"/home/vmadmin/myenv/English/clip3.mp3\"\n",
    "waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Define the chunk duration in seconds\n",
    "chunk_duration = 10\n",
    "num_samples_per_chunk = chunk_duration * sample_rate\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Split the audio into chunks\n",
    "chunks = []\n",
    "for start in range(0, len(waveform), num_samples_per_chunk):\n",
    "    end = min(start + num_samples_per_chunk, len(waveform))\n",
    "    chunk = waveform[start:end]\n",
    "    chunks.append((chunk, start / sample_rate, end / sample_rate))  # Include timestamps\n",
    "\n",
    "# Transcribe each chunk\n",
    "transcriptions = []\n",
    "for i, (chunk, start_time_chunk, end_time_chunk) in enumerate(chunks):\n",
    "    # Save the chunk to a temporary file\n",
    "    chunk_file = f\"temp_chunk_{i}.wav\"\n",
    "    sf.write(chunk_file, chunk, sample_rate)\n",
    "\n",
    "    # Run the ASR pipeline on the chunk\n",
    "    result = pipe(chunk_file, batch_size=8, return_timestamps=True)  # Set to True for timestamps\n",
    "    transcriptions.append((result[\"text\"], start_time_chunk, end_time_chunk))\n",
    "\n",
    "# Stop timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Print the transcriptions with timestamps\n",
    "for text, start_time_chunk, end_time_chunk in transcriptions:\n",
    "    print(f\"[{start_time_chunk:.2f}s - {end_time_chunk:.2f}s] {text}\")\n",
    "\n",
    "# Optional: Combine transcriptions if needed\n",
    "full_transcription = \" \".join(text for text, _, _ in transcriptions)\n",
    "print(\"\\nFull Transcription:\")\n",
    "print(full_transcription)\n",
    "\n",
    "# Print total processed time\n",
    "print(f\"\\nTotal Processing Time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e47da92d-e3d8-4eb0-87a6-68d4ee086d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16955/3334939460.py:3: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "[src/libmpg123/parse.c:skip_junk():1276] error: Giving up searching valid MPEG header after 65536 bytes of junk.\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s - 10.00s]  We are struggling with some issues. There's a big debate in this country, in our country, about manufacturing. Now the fact is, I mean there are people who would\n",
      "[10.00s - 20.00s]  why we're importing so much from China? Part of it is because we neglected manufacturing through the 1960s, 70s, 80s and 90s.\n",
      "[20.00s - 30.00s]  maybe even the first decade of 2000. When you, I mean, think back, I mean, all of you are as connected and have as good a memory about our country as I\n",
      "[30.00s - 40.00s]  when did we actually have governments who made a major push on manufacturing and let the people who today come and say no we need to find a fix\n",
      "[40.00s - 50.00s]  as though it's something you can do instead in mystery. In fact, and rather, other people who actually also say that we are incapable of it. We should not even attempt it.\n",
      "[50.00s - 60.00s]  So, now ask yourself, can you actually be a major power in the world without manufacturing?\n",
      "[60.00s - 70.00s]  because a major power needs technology. Nobody can develop technology without developing manufacturing.\n",
      "[70.00s - 80.00s]  you have that strain of thought also. So, as I said, you know, it's, it requires, until we develop the human resources, it requires hard work.\n",
      "[80.00s - 90.00s]  until you build the infrastructure, until you have those policies. So life is not khattah kha. Life is hard work.\n",
      "[90.00s - 96.34s]  Life is diligence. Anybody who's held a job and labelled at it, knows it.\n",
      "\n",
      "Full Transcription:\n",
      " We are struggling with some issues. There's a big debate in this country, in our country, about manufacturing. Now the fact is, I mean there are people who would  why we're importing so much from China? Part of it is because we neglected manufacturing through the 1960s, 70s, 80s and 90s.  maybe even the first decade of 2000. When you, I mean, think back, I mean, all of you are as connected and have as good a memory about our country as I  when did we actually have governments who made a major push on manufacturing and let the people who today come and say no we need to find a fix  as though it's something you can do instead in mystery. In fact, and rather, other people who actually also say that we are incapable of it. We should not even attempt it.  So, now ask yourself, can you actually be a major power in the world without manufacturing?  because a major power needs technology. Nobody can develop technology without developing manufacturing.  you have that strain of thought also. So, as I said, you know, it's, it requires, until we develop the human resources, it requires hard work.  until you build the infrastructure, until you have those policies. So life is not khattah kha. Life is hard work.  Life is diligence. Anybody who's held a job and labelled at it, knows it.\n",
      "\n",
      "Total Processing Time: 2.48 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the audio file using librosa\n",
    "audio_file = \"/home/vmadmin/myenv/English/clip4.mp3\"\n",
    "waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Define the chunk duration in seconds\n",
    "chunk_duration = 10\n",
    "num_samples_per_chunk = chunk_duration * sample_rate\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Split the audio into chunks\n",
    "chunks = []\n",
    "for start in range(0, len(waveform), num_samples_per_chunk):\n",
    "    end = min(start + num_samples_per_chunk, len(waveform))\n",
    "    chunk = waveform[start:end]\n",
    "    chunks.append((chunk, start / sample_rate, end / sample_rate))  # Include timestamps\n",
    "\n",
    "# Transcribe each chunk\n",
    "transcriptions = []\n",
    "for i, (chunk, start_time_chunk, end_time_chunk) in enumerate(chunks):\n",
    "    # Save the chunk to a temporary file\n",
    "    chunk_file = f\"temp_chunk_{i}.wav\"\n",
    "    sf.write(chunk_file, chunk, sample_rate)\n",
    "\n",
    "    # Run the ASR pipeline on the chunk\n",
    "    result = pipe(chunk_file, batch_size=8, return_timestamps=True)  # Set to True for timestamps\n",
    "    transcriptions.append((result[\"text\"], start_time_chunk, end_time_chunk))\n",
    "\n",
    "# Stop timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Print the transcriptions with timestamps\n",
    "for text, start_time_chunk, end_time_chunk in transcriptions:\n",
    "    print(f\"[{start_time_chunk:.2f}s - {end_time_chunk:.2f}s] {text}\")\n",
    "\n",
    "# Optional: Combine transcriptions if needed\n",
    "full_transcription = \" \".join(text for text, _, _ in transcriptions)\n",
    "print(\"\\nFull Transcription:\")\n",
    "print(full_transcription)\n",
    "\n",
    "# Print total processed time\n",
    "print(f\"\\nTotal Processing Time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d684245f-d9bd-45f7-8f02-1ad856e0aaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s - 10.00s]  on this former industrial site in Whitehaven, Cumbria, planned to produce 60 million tonnes of new coal. But since it was approved, a Supreme Court ruling found projects\n",
      "[10.00s - 20.00s]  consider carbon emissions from burning fossil fuels, not just digging them up. The mine was the first legal test of that. It's been a really important victory.\n",
      "[20.00s - 30.00s]  But what frustrates me most is that the years local decision makers have been putting all their efforts and fighting for a coal mine in Whitehaven. They could have spent that time investing in green jobs.\n",
      "[30.00s - 40.00s]  But it was mining jobs the community expected. This site has sat empty for 20 years. It's devastating for the community. The jobs that were going to be created were\n",
      "[40.00s - 50.00s]  Possibly in the construction and supply chain surrounding it were probably around 2000. And the long-term, well-paid jobs for running the facility work.\n",
      "[50.00s - 60.00s]  in excess of 500. The new government has been clear about its net zero ambitions, but judgments like this one could test them. We're still reliance on\n",
      "[60.00s - 60.01s]  I'm going to be.\n",
      "\n",
      "Full Transcription:\n",
      " on this former industrial site in Whitehaven, Cumbria, planned to produce 60 million tonnes of new coal. But since it was approved, a Supreme Court ruling found projects  consider carbon emissions from burning fossil fuels, not just digging them up. The mine was the first legal test of that. It's been a really important victory.  But what frustrates me most is that the years local decision makers have been putting all their efforts and fighting for a coal mine in Whitehaven. They could have spent that time investing in green jobs.  But it was mining jobs the community expected. This site has sat empty for 20 years. It's devastating for the community. The jobs that were going to be created were  Possibly in the construction and supply chain surrounding it were probably around 2000. And the long-term, well-paid jobs for running the facility work.  in excess of 500. The new government has been clear about its net zero ambitions, but judgments like this one could test them. We're still reliance on  I'm going to be.\n",
      "\n",
      "Total Processing Time: 1.81 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the audio file using librosa\n",
    "audio_file = \"/home/vmadmin/myenv/English/1010834_2024.09.14_08.06.27-2024.09.14_08.07.27.wav\"\n",
    "waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Define the chunk duration in seconds\n",
    "chunk_duration = 10\n",
    "num_samples_per_chunk = chunk_duration * sample_rate\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Split the audio into chunks\n",
    "chunks = []\n",
    "for start in range(0, len(waveform), num_samples_per_chunk):\n",
    "    end = min(start + num_samples_per_chunk, len(waveform))\n",
    "    chunk = waveform[start:end]\n",
    "    chunks.append((chunk, start / sample_rate, end / sample_rate))  # Include timestamps\n",
    "\n",
    "# Transcribe each chunk\n",
    "transcriptions = []\n",
    "for i, (chunk, start_time_chunk, end_time_chunk) in enumerate(chunks):\n",
    "    # Save the chunk to a temporary file\n",
    "    chunk_file = f\"temp_chunk_{i}.wav\"\n",
    "    sf.write(chunk_file, chunk, sample_rate)\n",
    "\n",
    "    # Run the ASR pipeline on the chunk\n",
    "    result = pipe(chunk_file, batch_size=8, return_timestamps=True)  # Set to True for timestamps\n",
    "    transcriptions.append((result[\"text\"], start_time_chunk, end_time_chunk))\n",
    "\n",
    "# Stop timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Print the transcriptions with timestamps\n",
    "for text, start_time_chunk, end_time_chunk in transcriptions:\n",
    "    print(f\"[{start_time_chunk:.2f}s - {end_time_chunk:.2f}s] {text}\")\n",
    "\n",
    "# Optional: Combine transcriptions if needed\n",
    "full_transcription = \" \".join(text for text, _, _ in transcriptions)\n",
    "print(\"\\nFull Transcription:\")\n",
    "print(full_transcription)\n",
    "\n",
    "# Print total processed time\n",
    "print(f\"\\nTotal Processing Time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3303821-3f70-42dc-99ea-c8c308cc6ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s - 10.00s]  content we flagged was taken down, but it's still possible to find more. A century old ideology of hate, pushed by cutting-edge algorithms,\n",
      "[10.00s - 20.00s]  to a massive, modern audience. Tom Cheshire, Sky News. The UK's High Court has reversed the decision to approve\n",
      "[20.00s - 30.00s]  the UK's first new coal mine in 30 years. It follows the confirmation this week that nearly 3,000 jobs will be lost at the Port Talbot Steelworks and potentially\n",
      "[30.00s - 40.00s]  potentially 400 at Scotland's only oil refinery Grangemouth. Our science and technology editor Tom Clark reports now on the UK's changing\n",
      "[40.00s - 50.00s]  credentials. Leave it in the ground. Leave it in the ground. Their case argued UK coal has no future on a rapidly warming\n",
      "[50.00s - 60.00s]  We have won. The High Court pretty much agreed. It's a huge win. And this, the proposed coal mine that lost. The Woodhouse Colliery\n",
      "[60.00s - 60.01s]  Thank you.\n",
      "\n",
      "Full Transcription:\n",
      " content we flagged was taken down, but it's still possible to find more. A century old ideology of hate, pushed by cutting-edge algorithms,  to a massive, modern audience. Tom Cheshire, Sky News. The UK's High Court has reversed the decision to approve  the UK's first new coal mine in 30 years. It follows the confirmation this week that nearly 3,000 jobs will be lost at the Port Talbot Steelworks and potentially  potentially 400 at Scotland's only oil refinery Grangemouth. Our science and technology editor Tom Clark reports now on the UK's changing  credentials. Leave it in the ground. Leave it in the ground. Their case argued UK coal has no future on a rapidly warming  We have won. The High Court pretty much agreed. It's a huge win. And this, the proposed coal mine that lost. The Woodhouse Colliery  Thank you.\n",
      "\n",
      "Total Processing Time: 1.65 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the audio file using librosa\n",
    "audio_file = \"/home/vmadmin/myenv/English/1010834_2024.09.14_08.05.27-2024.09.14_08.06.27.wav\"\n",
    "waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Define the chunk duration in seconds\n",
    "chunk_duration = 10\n",
    "num_samples_per_chunk = chunk_duration * sample_rate\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Split the audio into chunks\n",
    "chunks = []\n",
    "for start in range(0, len(waveform), num_samples_per_chunk):\n",
    "    end = min(start + num_samples_per_chunk, len(waveform))\n",
    "    chunk = waveform[start:end]\n",
    "    chunks.append((chunk, start / sample_rate, end / sample_rate))  # Include timestamps\n",
    "\n",
    "# Transcribe each chunk\n",
    "transcriptions = []\n",
    "for i, (chunk, start_time_chunk, end_time_chunk) in enumerate(chunks):\n",
    "    # Save the chunk to a temporary file\n",
    "    chunk_file = f\"temp_chunk_{i}.wav\"\n",
    "    sf.write(chunk_file, chunk, sample_rate)\n",
    "\n",
    "    # Run the ASR pipeline on the chunk\n",
    "    result = pipe(chunk_file, batch_size=8, return_timestamps=True)  # Set to True for timestamps\n",
    "    transcriptions.append((result[\"text\"], start_time_chunk, end_time_chunk))\n",
    "\n",
    "# Stop timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Print the transcriptions with timestamps\n",
    "for text, start_time_chunk, end_time_chunk in transcriptions:\n",
    "    print(f\"[{start_time_chunk:.2f}s - {end_time_chunk:.2f}s] {text}\")\n",
    "\n",
    "# Optional: Combine transcriptions if needed\n",
    "full_transcription = \" \".join(text for text, _, _ in transcriptions)\n",
    "print(\"\\nFull Transcription:\")\n",
    "print(full_transcription)\n",
    "\n",
    "# Print total processed time\n",
    "print(f\"\\nTotal Processing Time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09cfbd25-18ae-4f66-83ce-65b1dc7f631e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s - 10.00s]  content to people who don't really understand but think it's cool or funny. However, the impact on the victim is the same, which is the kind of experience of hate of minority\n",
      "[10.00s - 20.00s]  communities. This is one of the musicians whose songs have been bolted on to Nazi content without their knowledge.\n",
      "[20.00s - 30.00s]  Algois told us I was not previously aware that my music was being used in this way and I find it shocking and deplorable.\n",
      "[30.00s - 40.00s]  Sky News previously reported about Islamic state supporters using the same sounds loophole to gain more traction on TikTok. We forwarded all the Nazi videos\n",
      "[40.00s - 50.00s]  we found this time to TikTok and asked the company for comment. A spokesperson told us, this content was immediately removed for breaching our strict policies against hate speech.\n",
      "[50.00s - 60.00s]  train our safety professionals and update our safeguards to detect hateful behaviour on an ongoing basis, and we remove 91% of this type of content before it is reported to us.\n",
      "[60.00s - 60.01s]  I'm going to be.\n",
      "\n",
      "Full Transcription:\n",
      " content to people who don't really understand but think it's cool or funny. However, the impact on the victim is the same, which is the kind of experience of hate of minority  communities. This is one of the musicians whose songs have been bolted on to Nazi content without their knowledge.  Algois told us I was not previously aware that my music was being used in this way and I find it shocking and deplorable.  Sky News previously reported about Islamic state supporters using the same sounds loophole to gain more traction on TikTok. We forwarded all the Nazi videos  we found this time to TikTok and asked the company for comment. A spokesperson told us, this content was immediately removed for breaching our strict policies against hate speech.  train our safety professionals and update our safeguards to detect hateful behaviour on an ongoing basis, and we remove 91% of this type of content before it is reported to us.  I'm going to be.\n",
      "\n",
      "Total Processing Time: 1.64 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the audio file using librosa\n",
    "audio_file = \"/home/vmadmin/myenv/English/1010834_2024.09.14_08.04.27-2024.09.14_08.05.27.wav\"\n",
    "waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Define the chunk duration in seconds\n",
    "chunk_duration = 10\n",
    "num_samples_per_chunk = chunk_duration * sample_rate\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Split the audio into chunks\n",
    "chunks = []\n",
    "for start in range(0, len(waveform), num_samples_per_chunk):\n",
    "    end = min(start + num_samples_per_chunk, len(waveform))\n",
    "    chunk = waveform[start:end]\n",
    "    chunks.append((chunk, start / sample_rate, end / sample_rate))  # Include timestamps\n",
    "\n",
    "# Transcribe each chunk\n",
    "transcriptions = []\n",
    "for i, (chunk, start_time_chunk, end_time_chunk) in enumerate(chunks):\n",
    "    # Save the chunk to a temporary file\n",
    "    chunk_file = f\"temp_chunk_{i}.wav\"\n",
    "    sf.write(chunk_file, chunk, sample_rate)\n",
    "\n",
    "    # Run the ASR pipeline on the chunk\n",
    "    result = pipe(chunk_file, batch_size=8, return_timestamps=True)  # Set to True for timestamps\n",
    "    transcriptions.append((result[\"text\"], start_time_chunk, end_time_chunk))\n",
    "\n",
    "# Stop timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Print the transcriptions with timestamps\n",
    "for text, start_time_chunk, end_time_chunk in transcriptions:\n",
    "    print(f\"[{start_time_chunk:.2f}s - {end_time_chunk:.2f}s] {text}\")\n",
    "\n",
    "# Optional: Combine transcriptions if needed\n",
    "full_transcription = \" \".join(text for text, _, _ in transcriptions)\n",
    "print(\"\\nFull Transcription:\")\n",
    "print(full_transcription)\n",
    "\n",
    "# Print total processed time\n",
    "print(f\"\\nTotal Processing Time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b92c9ca-0c2c-43ac-a6a4-8f49ffb0e42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s - 10.00s]  content to people who don't really understand but think it's cool or funny. However, the impact on the victim is the same, which is the kind of experience of hate of minority\n",
      "[10.00s - 20.00s]  communities. This is one of the musicians whose songs have been bolted on to Nazi content without their knowledge.\n",
      "[20.00s - 30.00s]  Algois told us I was not previously aware that my music was being used in this way and I find it shocking and deplorable.\n",
      "[30.00s - 40.00s]  Sky News previously reported about Islamic state supporters using the same sounds loophole to gain more traction on TikTok. We forwarded all the Nazi videos\n",
      "[40.00s - 50.00s]  we found this time to TikTok and asked the company for comment. A spokesperson told us, this content was immediately removed for breaching our strict policies against hate speech.\n",
      "[50.00s - 60.00s]  train our safety professionals and update our safeguards to detect hateful behaviour on an ongoing basis, and we remove 91% of this type of content before it is reported to us.\n",
      "[60.00s - 60.01s]  I'm going to be.\n",
      "\n",
      "Full Transcription:\n",
      " content to people who don't really understand but think it's cool or funny. However, the impact on the victim is the same, which is the kind of experience of hate of minority  communities. This is one of the musicians whose songs have been bolted on to Nazi content without their knowledge.  Algois told us I was not previously aware that my music was being used in this way and I find it shocking and deplorable.  Sky News previously reported about Islamic state supporters using the same sounds loophole to gain more traction on TikTok. We forwarded all the Nazi videos  we found this time to TikTok and asked the company for comment. A spokesperson told us, this content was immediately removed for breaching our strict policies against hate speech.  train our safety professionals and update our safeguards to detect hateful behaviour on an ongoing basis, and we remove 91% of this type of content before it is reported to us.  I'm going to be.\n",
      "\n",
      "Total Processing Time: 1.82 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the audio file using librosa\n",
    "audio_file = \"/home/vmadmin/myenv/English/1010834_2024.09.14_08.04.27-2024.09.14_08.05.27.wav\"\n",
    "waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Define the chunk duration in seconds\n",
    "chunk_duration = 10\n",
    "num_samples_per_chunk = chunk_duration * sample_rate\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Split the audio into chunks\n",
    "chunks = []\n",
    "for start in range(0, len(waveform), num_samples_per_chunk):\n",
    "    end = min(start + num_samples_per_chunk, len(waveform))\n",
    "    chunk = waveform[start:end]\n",
    "    chunks.append((chunk, start / sample_rate, end / sample_rate))  # Include timestamps\n",
    "\n",
    "# Transcribe each chunk\n",
    "transcriptions = []\n",
    "for i, (chunk, start_time_chunk, end_time_chunk) in enumerate(chunks):\n",
    "    # Save the chunk to a temporary file\n",
    "    chunk_file = f\"temp_chunk_{i}.wav\"\n",
    "    sf.write(chunk_file, chunk, sample_rate)\n",
    "\n",
    "    # Run the ASR pipeline on the chunk\n",
    "    result = pipe(chunk_file, batch_size=8, return_timestamps=True)  # Set to True for timestamps\n",
    "    transcriptions.append((result[\"text\"], start_time_chunk, end_time_chunk))\n",
    "\n",
    "# Stop timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Print the transcriptions with timestamps\n",
    "for text, start_time_chunk, end_time_chunk in transcriptions:\n",
    "    print(f\"[{start_time_chunk:.2f}s - {end_time_chunk:.2f}s] {text}\")\n",
    "\n",
    "# Optional: Combine transcriptions if needed\n",
    "full_transcription = \" \".join(text for text, _, _ in transcriptions)\n",
    "print(\"\\nFull Transcription:\")\n",
    "print(full_transcription)\n",
    "\n",
    "# Print total processed time\n",
    "print(f\"\\nTotal Processing Time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b7a626c-81d4-401f-9a09-2004b30c5b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s - 10.00s]  Nazi speeches and marching music have been used as background sound on tens of thousands of TikTok videos as far-right groups try and spread their\n",
      "[10.00s - 20.00s]  message. To appeal to a wider audience, most of the speeches are set to a type of music popular on TikTok called DriftFon.\n",
      "[20.00s - 30.00s]  without the creator's permission or knowledge. And that could be all sorts, cat videos, gym posts, gaming or cars here. There's a few of the most popular categories we have seen\n",
      "[30.00s - 40.00s]  It's a way to get content shared widely before offering the user more sinister stuff if they hit the sound button in the corner of a post, which shows them other videos using the same sound.\n",
      "[40.00s - 50.00s]  For example, this is a more innocuous video of a cat that looks like Hitler. We'll put that back into the stack, and this is a huge stack here. Have a look at another type we've seen gaming. This video was made\n",
      "[50.00s - 60.00s]  using Minecraft, the German dictator, recreated in the game. Now, this is popular with children and the owner of Minecraft. Microsoft told us that hate speech and terrorist content is\n",
      "\n",
      "Full Transcription:\n",
      " Nazi speeches and marching music have been used as background sound on tens of thousands of TikTok videos as far-right groups try and spread their  message. To appeal to a wider audience, most of the speeches are set to a type of music popular on TikTok called DriftFon.  without the creator's permission or knowledge. And that could be all sorts, cat videos, gym posts, gaming or cars here. There's a few of the most popular categories we have seen  It's a way to get content shared widely before offering the user more sinister stuff if they hit the sound button in the corner of a post, which shows them other videos using the same sound.  For example, this is a more innocuous video of a cat that looks like Hitler. We'll put that back into the stack, and this is a huge stack here. Have a look at another type we've seen gaming. This video was made  using Minecraft, the German dictator, recreated in the game. Now, this is popular with children and the owner of Minecraft. Microsoft told us that hate speech and terrorist content is\n",
      "\n",
      "Total Processing Time: 1.68 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the audio file using librosa\n",
    "audio_file = \"/home/vmadmin/myenv/English/1010834_2024.09.14_08.02.27-2024.09.14_08.03.27.wav\"\n",
    "waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Define the chunk duration in seconds\n",
    "chunk_duration = 10\n",
    "num_samples_per_chunk = chunk_duration * sample_rate\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Split the audio into chunks\n",
    "chunks = []\n",
    "for start in range(0, len(waveform), num_samples_per_chunk):\n",
    "    end = min(start + num_samples_per_chunk, len(waveform))\n",
    "    chunk = waveform[start:end]\n",
    "    chunks.append((chunk, start / sample_rate, end / sample_rate))  # Include timestamps\n",
    "\n",
    "# Transcribe each chunk\n",
    "transcriptions = []\n",
    "for i, (chunk, start_time_chunk, end_time_chunk) in enumerate(chunks):\n",
    "    # Save the chunk to a temporary file\n",
    "    chunk_file = f\"temp_chunk_{i}.wav\"\n",
    "    sf.write(chunk_file, chunk, sample_rate)\n",
    "\n",
    "    # Run the ASR pipeline on the chunk\n",
    "    result = pipe(chunk_file, batch_size=8, return_timestamps=True)  # Set to True for timestamps\n",
    "    transcriptions.append((result[\"text\"], start_time_chunk, end_time_chunk))\n",
    "\n",
    "# Stop timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Print the transcriptions with timestamps\n",
    "for text, start_time_chunk, end_time_chunk in transcriptions:\n",
    "    print(f\"[{start_time_chunk:.2f}s - {end_time_chunk:.2f}s] {text}\")\n",
    "\n",
    "# Optional: Combine transcriptions if needed\n",
    "full_transcription = \" \".join(text for text, _, _ in transcriptions)\n",
    "print(\"\\nFull Transcription:\")\n",
    "print(full_transcription)\n",
    "\n",
    "# Print total processed time\n",
    "print(f\"\\nTotal Processing Time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95330ed9-4616-4db7-935c-66b7eb1ff6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s - 10.00s]  assembly seats and in second and third phase primates would be campaigning in Riyasi district in Katra Vashemata\n",
      "[10.00s - 20.00s]  the reconnaissance, Qutwa, Jammu. So, an extensive campaigning. Hormrishah has already addressed frilly's here. He is coming here again in next few days.\n",
      "[20.00s - 30.00s]  So, other senior leaders, BJP President, JAPNEDA, Defense Minister Rajna Singh recently addressed Riley in Ramban and Banha as well.\n",
      "[30.00s - 40.00s]  So, top leaders, top guns of the BJP are campaigning in Jhman, Kashmir as the first phase of polling is approaching to just four days away.\n",
      "[40.00s - 50.00s]  Now, Zheer, stay on with us. There's some more news coming in from Jammu and Kashmir. Like you had mentioned, there was an encounter that took place in Jambun Kishmi right ahead of the Prime Minister's visit three.\n",
      "[50.00s - 60.00s]  separate encounters in fact in Kishwar two soldiers have unfortunately died two terrorists were killed in Katwa in the encounter and an encounter underway in Barabullah\n",
      "[60.00s - 60.03s]  I'm\n",
      "\n",
      "Full Transcription:\n",
      " assembly seats and in second and third phase primates would be campaigning in Riyasi district in Katra Vashemata  the reconnaissance, Qutwa, Jammu. So, an extensive campaigning. Hormrishah has already addressed frilly's here. He is coming here again in next few days.  So, other senior leaders, BJP President, JAPNEDA, Defense Minister Rajna Singh recently addressed Riley in Ramban and Banha as well.  So, top leaders, top guns of the BJP are campaigning in Jhman, Kashmir as the first phase of polling is approaching to just four days away.  Now, Zheer, stay on with us. There's some more news coming in from Jammu and Kashmir. Like you had mentioned, there was an encounter that took place in Jambun Kishmi right ahead of the Prime Minister's visit three.  separate encounters in fact in Kishwar two soldiers have unfortunately died two terrorists were killed in Katwa in the encounter and an encounter underway in Barabullah  I'm\n",
      "\n",
      "Total Processing Time: 1.79 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the audio file using librosa\n",
    "audio_file = \"/home/vmadmin/myenv/English/1010259_2024.09.14_08.04.28-2024.09.14_08.05.28.wav\"\n",
    "waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Define the chunk duration in seconds\n",
    "chunk_duration = 10\n",
    "num_samples_per_chunk = chunk_duration * sample_rate\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Split the audio into chunks\n",
    "chunks = []\n",
    "for start in range(0, len(waveform), num_samples_per_chunk):\n",
    "    end = min(start + num_samples_per_chunk, len(waveform))\n",
    "    chunk = waveform[start:end]\n",
    "    chunks.append((chunk, start / sample_rate, end / sample_rate))  # Include timestamps\n",
    "\n",
    "# Transcribe each chunk\n",
    "transcriptions = []\n",
    "for i, (chunk, start_time_chunk, end_time_chunk) in enumerate(chunks):\n",
    "    # Save the chunk to a temporary file\n",
    "    chunk_file = f\"temp_chunk_{i}.wav\"\n",
    "    sf.write(chunk_file, chunk, sample_rate)\n",
    "\n",
    "    # Run the ASR pipeline on the chunk\n",
    "    result = pipe(chunk_file, batch_size=8, return_timestamps=True)  # Set to True for timestamps\n",
    "    transcriptions.append((result[\"text\"], start_time_chunk, end_time_chunk))\n",
    "\n",
    "# Stop timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Print the transcriptions with timestamps\n",
    "for text, start_time_chunk, end_time_chunk in transcriptions:\n",
    "    print(f\"[{start_time_chunk:.2f}s - {end_time_chunk:.2f}s] {text}\")\n",
    "\n",
    "# Optional: Combine transcriptions if needed\n",
    "full_transcription = \" \".join(text for text, _, _ in transcriptions)\n",
    "print(\"\\nFull Transcription:\")\n",
    "print(full_transcription)\n",
    "\n",
    "# Print total processed time\n",
    "print(f\"\\nTotal Processing Time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a9149aa-58c3-4b70-a87e-9c8b029166a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s - 10.00s]  popular with children and the owner of Minecraft, Microsoft told us that hate speech and terrorist content is strictly forbidden and they take action to remove such content. But on TikTok, there are posts\n",
      "[10.00s - 20.00s]  that are just two graphic to show, specifically anti-Semitic. We've blurred this one here, which shows images from gas chambers, set to the same type of audio. And there's much more of this graphic\n",
      "[20.00s - 30.00s]  type of contact. In fact, Sky News has seen 72,000 posts used in this way. Not only is that number big, but the level of engagement is high too.\n",
      "[30.00s - 40.00s]  Between them, these posts have racked up 21 million likes, showing people are engaging with the videos. Well, how are they engaging? This is a good example, an image of a Nuremberg rally.\n",
      "[40.00s - 50.00s]  accompanied by a hitler speech, it's been liked by more than 56,000 users. And in a comment, there's been liked 1,695 times, one user states, modern 20s,\n",
      "[50.00s - 60.00s]  society needs him. Another says, we miss you. It's difficult to know the motivations of the people posting it. It's probably a range from people who are knowingly spreading white national\n",
      "[60.00s - 60.01s]  Thank you.\n",
      "\n",
      "Full Transcription:\n",
      " popular with children and the owner of Minecraft, Microsoft told us that hate speech and terrorist content is strictly forbidden and they take action to remove such content. But on TikTok, there are posts  that are just two graphic to show, specifically anti-Semitic. We've blurred this one here, which shows images from gas chambers, set to the same type of audio. And there's much more of this graphic  type of contact. In fact, Sky News has seen 72,000 posts used in this way. Not only is that number big, but the level of engagement is high too.  Between them, these posts have racked up 21 million likes, showing people are engaging with the videos. Well, how are they engaging? This is a good example, an image of a Nuremberg rally.  accompanied by a hitler speech, it's been liked by more than 56,000 users. And in a comment, there's been liked 1,695 times, one user states, modern 20s,  society needs him. Another says, we miss you. It's difficult to know the motivations of the people posting it. It's probably a range from people who are knowingly spreading white national  Thank you.\n",
      "\n",
      "Total Processing Time: 1.87 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the audio file using librosa\n",
    "audio_file = \"/home/vmadmin/myenv/English/1010834_2024.09.14_08.03.27-2024.09.14_08.04.27.wav\"\n",
    "waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Define the chunk duration in seconds\n",
    "chunk_duration = 10\n",
    "num_samples_per_chunk = chunk_duration * sample_rate\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Split the audio into chunks\n",
    "chunks = []\n",
    "for start in range(0, len(waveform), num_samples_per_chunk):\n",
    "    end = min(start + num_samples_per_chunk, len(waveform))\n",
    "    chunk = waveform[start:end]\n",
    "    chunks.append((chunk, start / sample_rate, end / sample_rate))  # Include timestamps\n",
    "\n",
    "# Transcribe each chunk\n",
    "transcriptions = []\n",
    "for i, (chunk, start_time_chunk, end_time_chunk) in enumerate(chunks):\n",
    "    # Save the chunk to a temporary file\n",
    "    chunk_file = f\"temp_chunk_{i}.wav\"\n",
    "    sf.write(chunk_file, chunk, sample_rate)\n",
    "\n",
    "    # Run the ASR pipeline on the chunk\n",
    "    result = pipe(chunk_file, batch_size=8, return_timestamps=True)  # Set to True for timestamps\n",
    "    transcriptions.append((result[\"text\"], start_time_chunk, end_time_chunk))\n",
    "\n",
    "# Stop timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Print the transcriptions with timestamps\n",
    "for text, start_time_chunk, end_time_chunk in transcriptions:\n",
    "    print(f\"[{start_time_chunk:.2f}s - {end_time_chunk:.2f}s] {text}\")\n",
    "\n",
    "# Optional: Combine transcriptions if needed\n",
    "full_transcription = \" \".join(text for text, _, _ in transcriptions)\n",
    "print(\"\\nFull Transcription:\")\n",
    "print(full_transcription)\n",
    "\n",
    "# Print total processed time\n",
    "print(f\"\\nTotal Processing Time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e01b45f7-f7e9-4d1c-b5d1-22e35b17787b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s - 10.00s]  assembly seats and in second and third phase primates would be campaigning in Riyasi district in Katra Vashemata\n",
      "[10.00s - 20.00s]  the reconnaissance, Qutwa, Jammu. So, an extensive campaigning. Hormrishah has already addressed frilly's here. He is coming here again in next few days.\n",
      "[20.00s - 30.00s]  So, other senior leaders, BJP President, JAPNEDA, Defense Minister Rajna Singh recently addressed Riley in Ramban and Banha as well.\n",
      "[30.00s - 40.00s]  So, top leaders, top guns of the BJP are campaigning in Jhman, Kashmir as the first phase of polling is approaching to just four days away.\n",
      "[40.00s - 50.00s]  Now, Zheer, stay on with us. There's some more news coming in from Jammu and Kashmir. Like you had mentioned, there was an encounter that took place in Jambun Kishmi right ahead of the Prime Minister's visit three.\n",
      "[50.00s - 60.00s]  separate encounters in fact in Kishwar two soldiers have unfortunately died two terrorists were killed in Katwa in the encounter and an encounter underway in Barabullah\n",
      "[60.00s - 60.03s]  I'm\n",
      "\n",
      "Full Transcription:\n",
      " assembly seats and in second and third phase primates would be campaigning in Riyasi district in Katra Vashemata  the reconnaissance, Qutwa, Jammu. So, an extensive campaigning. Hormrishah has already addressed frilly's here. He is coming here again in next few days.  So, other senior leaders, BJP President, JAPNEDA, Defense Minister Rajna Singh recently addressed Riley in Ramban and Banha as well.  So, top leaders, top guns of the BJP are campaigning in Jhman, Kashmir as the first phase of polling is approaching to just four days away.  Now, Zheer, stay on with us. There's some more news coming in from Jammu and Kashmir. Like you had mentioned, there was an encounter that took place in Jambun Kishmi right ahead of the Prime Minister's visit three.  separate encounters in fact in Kishwar two soldiers have unfortunately died two terrorists were killed in Katwa in the encounter and an encounter underway in Barabullah  I'm\n",
      "\n",
      "Total Processing Time: 1.80 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the audio file using librosa\n",
    "audio_file = \"/home/vmadmin/myenv/English/1010259_2024.09.14_08.04.28-2024.09.14_08.05.28.wav\"\n",
    "waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Define the chunk duration in seconds\n",
    "chunk_duration = 10\n",
    "num_samples_per_chunk = chunk_duration * sample_rate\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Split the audio into chunks\n",
    "chunks = []\n",
    "for start in range(0, len(waveform), num_samples_per_chunk):\n",
    "    end = min(start + num_samples_per_chunk, len(waveform))\n",
    "    chunk = waveform[start:end]\n",
    "    chunks.append((chunk, start / sample_rate, end / sample_rate))  # Include timestamps\n",
    "\n",
    "# Transcribe each chunk\n",
    "transcriptions = []\n",
    "for i, (chunk, start_time_chunk, end_time_chunk) in enumerate(chunks):\n",
    "    # Save the chunk to a temporary file\n",
    "    chunk_file = f\"temp_chunk_{i}.wav\"\n",
    "    sf.write(chunk_file, chunk, sample_rate)\n",
    "\n",
    "    # Run the ASR pipeline on the chunk\n",
    "    result = pipe(chunk_file, batch_size=8, return_timestamps=True)  # Set to True for timestamps\n",
    "    transcriptions.append((result[\"text\"], start_time_chunk, end_time_chunk))\n",
    "\n",
    "# Stop timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Print the transcriptions with timestamps\n",
    "for text, start_time_chunk, end_time_chunk in transcriptions:\n",
    "    print(f\"[{start_time_chunk:.2f}s - {end_time_chunk:.2f}s] {text}\")\n",
    "\n",
    "# Optional: Combine transcriptions if needed\n",
    "full_transcription = \" \".join(text for text, _, _ in transcriptions)\n",
    "print(\"\\nFull Transcription:\")\n",
    "print(full_transcription)\n",
    "\n",
    "# Print total processed time\n",
    "print(f\"\\nTotal Processing Time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79b713e1-30ab-41aa-bc29-e2f9981a9d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s - 10.00s]  voters and galvanize them, get win seats for the BJP. Doda-Kistewar area is a very significant\n",
      "[10.00s - 20.00s]  important region for the BJP when it comes to increasing the number of seats in Jammu province. So besides addressing this rally in Duda,\n",
      "[20.00s - 30.00s]  and Kistvar and Ramban are part of it because it was essentially one district in until 2008 and then they\n",
      "[30.00s - 40.00s]  were two more districts where carved out of 12 Doda districts. So it has eight assembly segments and BJP is fighting from all the eight, even as\n",
      "[40.00s - 50.00s]  these are Muslim majority region, but some of the, during the delimitation, some of the conestrances have been carved out which have become\n",
      "[50.00s - 60.00s]  the Hindu majority seats of BJP is hoping to win big in from this this election from Doda, Kishdwa-Ram and district which has 8\n",
      "[60.00s - 60.03s]  Thank you.\n",
      "\n",
      "Full Transcription:\n",
      " voters and galvanize them, get win seats for the BJP. Doda-Kistewar area is a very significant  important region for the BJP when it comes to increasing the number of seats in Jammu province. So besides addressing this rally in Duda,  and Kistvar and Ramban are part of it because it was essentially one district in until 2008 and then they  were two more districts where carved out of 12 Doda districts. So it has eight assembly segments and BJP is fighting from all the eight, even as  these are Muslim majority region, but some of the, during the delimitation, some of the conestrances have been carved out which have become  the Hindu majority seats of BJP is hoping to win big in from this this election from Doda, Kishdwa-Ram and district which has 8  Thank you.\n",
      "\n",
      "Total Processing Time: 1.63 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the audio file using librosa\n",
    "audio_file = \"/home/vmadmin/myenv/English/1010259_2024.09.14_08.03.28-2024.09.14_08.04.28.wav\"\n",
    "waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Define the chunk duration in seconds\n",
    "chunk_duration = 10\n",
    "num_samples_per_chunk = chunk_duration * sample_rate\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Split the audio into chunks\n",
    "chunks = []\n",
    "for start in range(0, len(waveform), num_samples_per_chunk):\n",
    "    end = min(start + num_samples_per_chunk, len(waveform))\n",
    "    chunk = waveform[start:end]\n",
    "    chunks.append((chunk, start / sample_rate, end / sample_rate))  # Include timestamps\n",
    "\n",
    "# Transcribe each chunk\n",
    "transcriptions = []\n",
    "for i, (chunk, start_time_chunk, end_time_chunk) in enumerate(chunks):\n",
    "    # Save the chunk to a temporary file\n",
    "    chunk_file = f\"temp_chunk_{i}.wav\"\n",
    "    sf.write(chunk_file, chunk, sample_rate)\n",
    "\n",
    "    # Run the ASR pipeline on the chunk\n",
    "    result = pipe(chunk_file, batch_size=8, return_timestamps=True)  # Set to True for timestamps\n",
    "    transcriptions.append((result[\"text\"], start_time_chunk, end_time_chunk))\n",
    "\n",
    "# Stop timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Print the transcriptions with timestamps\n",
    "for text, start_time_chunk, end_time_chunk in transcriptions:\n",
    "    print(f\"[{start_time_chunk:.2f}s - {end_time_chunk:.2f}s] {text}\")\n",
    "\n",
    "# Optional: Combine transcriptions if needed\n",
    "full_transcription = \" \".join(text for text, _, _ in transcriptions)\n",
    "print(\"\\nFull Transcription:\")\n",
    "print(full_transcription)\n",
    "\n",
    "# Print total processed time\n",
    "print(f\"\\nTotal Processing Time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "074132f5-6d30-4539-8ffc-cd0db3f1b5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s - 10.00s]  to be addressed by the Prime Minister in Duda near Khrushhtwar of Jammun Kashmir ahead of the first phase of polling on the 18th of September. Now, Prime Minister Modi had last campaign for the BJP in the\n",
      "[10.00s - 20.00s]  Chenab region during the 2014 Assembly elections when the party had won four of the six seats. Remember the number of seats after delimitation has increased to eight. Ahead of the\n",
      "[20.00s - 30.00s]  minister's visit there was an encounter that broke out in Kishhtwar as well. The prime minister will be visiting Duda after 45 years at least. My colleague Nazir joins us with more details. Nazir, if you could take\n",
      "[30.00s - 40.00s]  take us through the Prime Minister's visit and the big campaign for the BJP in Japan-Kashmir. Well, it is Prime Minister Narinan Modi's first election\n",
      "[40.00s - 50.00s]  rally and in Jama and Kashmir's assembly elections four days ahead of the first phase of assembly polling so very significant\n",
      "[50.00s - 60.00s]  significant rally as far as the BJP's election campaign is concerned he's seen as the biggest vote catcher and who could move\n",
      "[60.00s - 60.02s]  I'm\n",
      "\n",
      "Full Transcription:\n",
      " to be addressed by the Prime Minister in Duda near Khrushhtwar of Jammun Kashmir ahead of the first phase of polling on the 18th of September. Now, Prime Minister Modi had last campaign for the BJP in the  Chenab region during the 2014 Assembly elections when the party had won four of the six seats. Remember the number of seats after delimitation has increased to eight. Ahead of the  minister's visit there was an encounter that broke out in Kishhtwar as well. The prime minister will be visiting Duda after 45 years at least. My colleague Nazir joins us with more details. Nazir, if you could take  take us through the Prime Minister's visit and the big campaign for the BJP in Japan-Kashmir. Well, it is Prime Minister Narinan Modi's first election  rally and in Jama and Kashmir's assembly elections four days ahead of the first phase of assembly polling so very significant  significant rally as far as the BJP's election campaign is concerned he's seen as the biggest vote catcher and who could move  I'm\n",
      "\n",
      "Total Processing Time: 2.11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/myenv/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the audio file using librosa\n",
    "audio_file = \"/home/vmadmin/myenv/English/1010259_2024.09.14_08.02.28-2024.09.14_08.03.28.wav\"\n",
    "waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Define the chunk duration in seconds\n",
    "chunk_duration = 10\n",
    "num_samples_per_chunk = chunk_duration * sample_rate\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Split the audio into chunks\n",
    "chunks = []\n",
    "for start in range(0, len(waveform), num_samples_per_chunk):\n",
    "    end = min(start + num_samples_per_chunk, len(waveform))\n",
    "    chunk = waveform[start:end]\n",
    "    chunks.append((chunk, start / sample_rate, end / sample_rate))  # Include timestamps\n",
    "\n",
    "# Transcribe each chunk\n",
    "transcriptions = []\n",
    "for i, (chunk, start_time_chunk, end_time_chunk) in enumerate(chunks):\n",
    "    # Save the chunk to a temporary file\n",
    "    chunk_file = f\"temp_chunk_{i}.wav\"\n",
    "    sf.write(chunk_file, chunk, sample_rate)\n",
    "\n",
    "    # Run the ASR pipeline on the chunk\n",
    "    result = pipe(chunk_file, batch_size=8, return_timestamps=True)  # Set to True for timestamps\n",
    "    transcriptions.append((result[\"text\"], start_time_chunk, end_time_chunk))\n",
    "\n",
    "# Stop timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Print the transcriptions with timestamps\n",
    "for text, start_time_chunk, end_time_chunk in transcriptions:\n",
    "    print(f\"[{start_time_chunk:.2f}s - {end_time_chunk:.2f}s] {text}\")\n",
    "\n",
    "# Optional: Combine transcriptions if needed\n",
    "full_transcription = \" \".join(text for text, _, _ in transcriptions)\n",
    "print(\"\\nFull Transcription:\")\n",
    "print(full_transcription)\n",
    "\n",
    "# Print total processed time\n",
    "print(f\"\\nTotal Processing Time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcccd79-963d-4414-83d4-35db78ea3c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
